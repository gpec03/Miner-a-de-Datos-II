---
title: "Clasificación y Análisis de Noticias Económicas, Políticas e Internacionales: Un Enfoque de Minería de Texto y Clasificación"
author:
- '* Gaya Enriquez Coronel'
- '* Nataly Huanca Choque'
- '* Valeria Rodriguez Segaline'
date: "5 Junio 2024"
output:
  html_document:
    df_print: paged
  pdf_document: default
---
# Resumen

En este trabajo se desarrolla un clasificador de noticias de las secciones de economía, política e internacional de diferentes periódicos digitales de Bolivia. Utilizando técnicas de raspado web y minería de texto, se entrenó un modelo de clasificación basado en el algoritmo de Naive Bayes. Los resultados muestran una precisión del 50.63%, destacando la necesidad de mejoras adicionales en la clasificación de ciertas categorías de noticias.

**Palabras clave**: Raspado web, Minería de texto, Método de clasificación Naive Bayes, Método CART, Base de datos

**Códigos JEL**: C55, C81, L82, C63, C88

## 1. Introducción
En el presente proyecto se realiza un clasificador de noticias de la sección de economía, política e internacional con el objetivo de clasificar noticias e interpretar las palabras más influyentes de cada noticia extraída. De este modo, este clasificador nos sirve para categorizar el tipo de palabras más influyentes además que se usa los tópicos aprendidos en la materia junto con la herramienta. 

# 2. Objetivos

## 2.1 Objetivo general 
Desarrollar un clasificador de noticias que realice un raspado web de diferentes periódicos para incluirlos en una base de datos y de esta manera, identificar las palabras más influyentes en cada noticia en las secciones mencionadas. 

## 2.2 Objetivos específicos
* Determinar el tipo de método de clasificación para la categorización de noticias. 
* Analizar diferentes tópicos de la materia como, minería de texto, scraping web, método de clasificación (Naive Bayes). * Identificar las noticias de los periódicos donde tiene la sección de economía, política e internacional. 
* Realizar analisis de minería de texto para identificar palabras influyentes.
* Sintetizar titulares y palabras repetidas mediante raspado web.

# 3. Motivación 

La motivación de este proyecto surge de la relevancia de la ciencia de datos en la carrera de Economía e inteligencia de negocios donde la ciencia de datos. La minería de texto y el raspado web son técnicas fundamentales para el análisis de datos, y su aplicación en este proyecto permite obtener resultados significativos en la clasificación de noticias de economía, política e internacional.Esto porque es necesario tener un clasificar de noticias de este tipo para los periódicos digitales que siempre realizan esta distinción y podrían tender a preguntarse dónde colocar sus noticias.  


# 4. Marco teórico

## 4.1 Revisión de la literatura

La revisión de la literatura se enfoca en el uso de técnicas de minería de datos para el análisis de noticias. En el artículo "Uso de minería de datos para analizar las tendencias de consumo de noticias locales" por Revista Razón y Palabra, se demuestra cómo herramientas como Google Analytics pueden extraer y analizar datos sobre el consumo de noticias en línea, identificando tendencias y patrones en el comportamiento de los lectores. Por otro lado, el trabajo titulado "Minería de Datos, Conflictos Sociales y explotación de Recursos Naturales" por CONICET, investiga la utilización de técnicas de minería de datos para procesar y analizar grandes volúmenes de noticias relacionadas con conflictos sociales y la explotación de recursos naturales en Argentina. Ambos artículos subrayan la importancia de la minería de datos para extraer información significativa y patrones de grandes volúmenes de texto, alineándose con los objetivos de nuestro proyecto, que busca categorizar y analizar noticias de economía, política e internacional utilizando técnicas similares.

## 4.2 Bases teóricas

A continuación, se detalla los temas aprendidos e involucrados en el proyecto como su definición, características, funciones entre otros. 

### 4.2.1 Raspado web

También llamado scraping web. El raspado web (web scraping) es la recolección automática de  información de los sitios web. Mediante el uso de API’s o scripts, se navega por páginas web y se recopila información específica, para ser procesada y analizada para diversos fines. Esta técnica permite obtener grandes cantidades de datos que pueden ser utilizados para análisis de mercado, investigación, vigilancia de precios, análisis de datos y más.

Sus características pueden ser:

- Automatización: El raspado web automatiza el proceso de recopilación de datos, reduciendo el tiempo y la comparación con la recolección manual.

- Eficiencia: Permite extraer grandes cantidades de datos de manera rápida y eficiente.

- Integración: Los datos extraídos se integran fácilmente con bases de datos y otras herramientas de análisis.

Una de sus funciones podría ser: la recopilación de datos, extrae datos estructurados de páginas web, como información de productos, precios, reseñas, y noticias y más. Recopila información de noticias y publicaciones para el seguimiento de temas y tendencias específicas. Facilita la recolección de grandes conjuntos de datos para investigaciones científicas y académicas.

### 4.2.2 Minería de texto

Sinónimo de análisis de texto el uso de minería de texto describe de forma adecuada el descubrimiento de ideas (KDD) y el uso de algoritmos específicos. Es el proceso de extraer información y patrones de grandes volúmenes de texto no estructurado, análisis estadístico y aprendizaje automático. Su objetivo es descubrir conocimientos ocultos, tendencias y relaciones en los datos textuales que no son evidentes a simple vista.

Sus características para la minería de texto son: 

* La confianza que se genera entre las partes interesadas para extraer información.
* Las metodologías se pueden aplicar rápidamente permitiendo métodos auditables y repetibles. 
* Extracción de conocimiento donde identifica patrones, tendencias y relaciones en los datos       textuales que pueden ser utilizados para la toma de decisiones.
* Identifica las nuevas ideas o refuerza la información relevante utilizando técnicas de           procesamiento de lenguaje natural (NLP), para comprender y analizar los resultados. 

Algunas de sus funciones son: 

- Clasificación de textos se categoriza documentos en diferentes clases o etiquetas predefinidas, como noticias de deportes, economía o política. 
- Detección de temas se descubre y agrupa temas recurrentes en un conjunto de documentos, proporcionando una visión general de los principales tópicos. 
- Análisis de tendencias donde identifica cambios y patrones en los datos textuales a lo largo del tiempo, útil para el análisis de mercado y la investigación.

**Tipos de minería de texto**

* **Bolsa de palabras**: La bolsa de palabras, también conocida como **bag-of-words**  o **n-gramas**, es un modelo simplificado utilizado en el **procesamiento de lenguaje natural (NLP)** y la minería de texto para representar textos como conjuntos de palabras independientes sin tener en cuenta el orden y la gramática. Un texto, como una oración o un documento se convierte en una colección o bolsa de sus palabras, donde se cuenta la frecuencia de cada palabra.

Se organizan en: 

+ DTM: Filas documentos, columnas palabras (tokenización)
+ TDM: Filas palabras (tokenización), columnas documentos

Donde el DTM es Document Term Matrix y el TDM es Term Document Matrix. La colección de documentos se llama corpus. 

* **Análisis sintético**: Es la sintaxis de las palabras donde representa un conjunto de reglas que definen los componentes de una oración. Utiliza técnicas de etiquetado para el discurso e identifica las palabras de la información adquirida en contexto gramatical. 

Se apoya de un tratamiento de texto donde sus pasos para constituir un ejemplo de minería de texto son: configuración del idioma, cargado de librerías, corpus de interés, limpieza de texto (mayúsculas, minúsculas, puntuación, espacios, números, etc.) y el armado de DTM o TDM. 


### 4.2.3 Métodos de clasificación 

Son los métodos más populares dentro de la minería de datos, principalmente por su aplicabilidad y adaptabilidad que contiene una gran variedad de técnicas. Donde la analítica predictiva es predecir un comportamiento futuro, los tipos de dataset son estructurados y no estructurados. Sus técnicas utilizadas son para asignar elementos a categorías basadas en sus características donde el análisis de datos y sus diversas aplicaciones, son la detección de fraudes y diagnósticos médicos, etc. 

Para su elaboración se necesita de las variables dependientes e independientes donde: 

* **Variables dependientes**: Son variables naturales  dentro de una población donde se estudia o existen en un dataset. Pueden ser de diferentes tipos, binarias, nominales y ordinales.

* **Variables independientes**: Determinan el momento de su elección con la variable dependiente. Son del tipo numérico, categórico entre otros. 

También se necesita de las bases de datos de entrenamiento y testeo:

* **Base de datos de entrenamiento**: Es el conjunto de datos utilizado para entrenar un modelo de aprendizaje. Durante el proceso de entrenamiento, el modelo identifica patrones y relaciones dentro de los datos, ajustando sus parámetros internos para minimizar el error y mejorar la precisión en la predicción.

Como característica son la calidad de datos que deben ser precisos, limpios y representativos del problema que se está tratando de resolver donde el etiquetado de la base de datos de entrenamiento debe estar etiquetado correctamente para el modelo. 

* **Base de datos de testeo**: Es el conjunto de datos utilizado para evaluar la precisión y generalización del modelo entrenado. Estos datos no se utilizan durante el proceso de entrenamiento, lo que permite una evaluación objetiva del rendimiento del modelo en datos no vistos previamente.

Por lo tanto,la independencia debe ser completamente independiente de la base de entrenamiento para evitar sesgos en la evaluación del modelo.

Para el presente proyecto del clasificador de noticias se usará el método de clasificación de Naive Bayes. 

### 4.2.3.1 Método de Naive Bayes

El método Naive Bayes es un clasificador probabilístico basado en el teorema de Bayes. Asume que las características son independientes entre sí, donde el simplificador hace que el clasificador sea muy eficiente. Donde este método nos demuestra la simplicidad y rapidez, funciona con grandes conjuntos de datos, requiere pocos datos para la estimación de parámetros. También por su simplicidad que es fácil de implementar y comprender.

### 4.2.3.2 Método de Clasificación CART de Árboles de Decisión

El método de Clasificación y Regresión de Árboles (CART) utiliza un árbol de decisión para predecir una variable objetivo basada en varios atributos de entrada. Divide repetidamente el conjunto de datos en subconjuntos basados en el atributo que mejor separa los datos, creando un árbol intuitivo y fácil de interpretar. Aunque es robusto y flexible, CART puede sobreajustarse, por lo que a menudo se emplean técnicas como la poda para mejorar su generalización.

# 5. Descripción de la base de datos

El proyecto utiliza una base de datos creada a partir de la información recopilada mediante raspado web de varios periódicos digitales de Bolivia. Los periódicos seleccionados son:

- La Razón: Uno de los periódicos más importantes de Bolivia, conocido por su cobertura en los ámbitos políticos, económicos y sociales del país.

- El Diario: El periódico más antiguo de Bolivia, con una línea editorial conservadora, ofrece noticias relevantes en diversas áreas, incluyendo economía y política.

- Economy: Especializado en noticias sobre negocios, finanzas y economía en Bolivia y Sudamérica, proporcionando análisis de mercado y noticias empresariales.

- El Mundo: Fundado en Santa Cruz de la Sierra, se enfoca en noticias locales, nacionales e internacionales, con una cobertura amplia en temas de política, economía y cultura.

Se recopilaron titulares de noticias de las secciones de economía, política e internacional de estos periódicos. Los datos extraídos incluyen los titulares y el texto completo de las noticias, que luego fueron procesados y analizados para identificar las palabras más influyentes y para la posterior clasificación mediante el modelo de Naive Bayes y el método CART de árboles de decisión.

# 6. Metodología

Para la elaboración del proyecto "Clasificador de noticias en la sección de economía, política e internacional" utilizando R, se han seguido varios pasos clave que incluyen el raspado web, la minería de texto y la aplicación del método de clasificación "Naive Bayes" y "cart". A continuación, se detallan estos procesos:

**Raspado Web**

El primer paso del proyecto fue realizar un raspado web de diferentes periódicos. El objetivo del raspado web fue extraer titulares de noticias de las secciones de economía, política e internacional de varios periódicos. Los periódicos seleccionados para este proyecto incluyen La Razón, El Diario, Economy y El Mundo.

- Selección de fuentes: Se identificaron los sitios web de cada tipo de periodico y se selecciona la sección de noticias al realizar el scraping web.

- Desarrollo del R: Se desarrollaron scripts en R utilizando bibliotecas como rvest para navegar por las páginas web de estos periódicos y extraer los titulares de las noticias. 

**Minería de texto** 

Una vez recopilados los datos, se procedió a la minería de texto para analizar y procesar los titulares extraídos. El proceso de minería de texto incluyó las siguientes etapas:

- Tokenización: Se dividieron los titulares en tokens individuales (palabras) utilizando la librería tm. Esto permitió transformar el texto en un formato que se pudiera analizar más fácilmente.

- Eliminación de Palabras Comunes: Se eliminaron las palabras comunes o "stopwords" que no aportan valor significativo al análisis.

- Frecuencia de Palabras: Se calculó la frecuencia de aparición de cada palabra en los titulares para identificar cuáles eran las más comunes y potencialmente influyentes, de acuerdo a esta frecuencia se crea una tabla de frecuencias.

- Construcción de Matrices: Se construyeron matrices de términos y documentos (DTM) para organizar y visualizar la frecuencia de las palabras en los diferentes titulares y categorías de noticias.


**Método de clasificación “Naive Bayes”**

El método de clasificación Naive Bayes se utilizó para categorizar las noticias en sus respectivas secciones. Este método probabilístico es eficiente y adecuado para este tipo de tareas debido a su simplicidad y efectividad. El proceso fue el siguiente:

- Se utilizó la base de datos de titulares ya tokenizados y limpiados para entrenar el modelo de Naive Bayes. Se empleó la librería e1071 para este propósito.

- Una vez entrenado, el modelo se utilizó para clasificar nuevos titulares. Para cada titular, el modelo calculaba la probabilidad de que perteneciera a una de las categorías (economía, política, internacional) basándose en las palabras presentes en el titular.

**Método CART (Árboles de Decisión)**

El método CART (Classification and Regression Trees) es una técnica de clasificación y regresión que utiliza árboles de decisión para predecir el valor de una variable objetivo basada en varias variables de entrada. Los árboles de decisión son modelos predictivos que se utilizan tanto para tareas de clasificación como de regresión. En el contexto de la clasificación de noticias, el método CART se emplea de la siguiente manera:

- Se construye un árbol de decisión basado en los datos de entrenamiento, donde cada nodo interno representa una prueba en una característica (por ejemplo, una palabra clave en el titular de la noticia), cada rama representa el resultado de la prueba, y cada nodo hoja representa una categoría de clase (economía, política, internacional).

- El árbol se entrena utilizando los titulares tokenizados y limpiados, y se emplea la librería rpart para este propósito.

- Una vez entrenado, el modelo de árbol de decisión se utiliza para clasificar nuevos titulares. Para cada titular, el árbol de decisión realiza una serie de pruebas basadas en las palabras presentes en el titular, y llega a una decisión sobre la categoría de la noticia.

- Este enfoque permite una interpretación visual y clara de cómo se toman las decisiones de clasificación, facilitando la identificación de las características más influyentes en la categorización de las noticias.

# 7. Resultados y análisis
Se realiza el primer summary donde nos refleja los siguientes datos: 

La matriz de confusión y las estadísticas proporcionan un rendimiento del modelo de clasificación. La precisión global del modelo es del 50.63 %, lo que indica que el modelo se clasifica correctamente. Sin embargo, existe una margen de precision donde se puede mejorar el modelo.

Para las seccione de economia nos muestra los siguientes resultados: Alta sensibilidad con un 92.28% nos sugiere que el modelo es muy efectivo para identificar correctamente las noticias de economía. Baja especificidad con un 23.56% indica que el modelo clasifica incorrectamente muchas noticias no económicas como económicas. La precisión balanceada con un 57.92% muestra un rendimiento razonable.

Otro resultado es el arbol de decisión donde es utilizado para clasificar noticias en las categorías de economía, internacional y política. Cada nodo del árbol representa una condición de decisión basada en palabras clave. Los colores de los nodos indican la categoría de la noticia con la mayor probabilidad:

- Economía: Color rojo.
- Internacional: Color gris.
- Política: Color verde.
Cada nodo también muestra las siguientes estadísticas: Número de instancias en cada categoría, porcentaje de precisión en la categoría predominante y las palabras clave que se utilizan para la decisión.

*Hojas del Árbol*

En cada hoja del árbol representa una categoría final (economía, internacional, política) con una precisión basada en la frecuencia de aparición de palabras clave en las noticias. En la seccion de "economía" tiene las estadísticas de 44 instancias correctas, 42 incorrectas y una precisión del 92%.

En la seccion de economía, con alta precisión nos muestra las palabras clave específicas como "pesado" y "bloqueos".

En la seccion de politica las palabras clave como "lider" y "anuncia" son indicadores efectivos para la clasificación en política, aunque la precisión aún puede mejorar.

# 8. Conclusiones

* El clasificador de noticias basado en el método de *Naive Bayes* demostró ser eficiente en la identificación de noticias en la seccion de economía, politica e internacional, con una alta sensibilidad del 92.28%. Sin embargo, mostró dificultades significativas en la clasificación de noticias internacionales, con una baja sensibilidad del 13.65%. Esto indica que mientras el modelo es bastante efectivo para ciertos tipos de noticias, requiere mejoras para ser más equilibrado y confiable en todas las categorías de las noticias.

* El uso del raspado web permitió la recolección efectiva de datos de diversas fuentes, como La Razón, El Diario, Economy y El Mundo. La minería de texto, incluyendo la tokenización y la eliminación de palabras comunes, fue crucial para preparar los datos para el modelo de clasificación. 

* Con una precisión global del modelo fue de 50.63%, lo que sugiere un rendimiento moderado. Para las noticias internacionales tiene un 98.10% de especificidad en las noticias y en la seccion de políticas un 95.96%, indicando que el modelo es bueno para identificar correctamente una noticia que no pertenece a estas categorías. 

* Por lo tanto, la baja precisión balanceada para las noticias internacionales con un 55.88% resalta la necesidad de mejorar el modelo para evitar clasificaciones incorrectas.

* La diversidad de las fuentes de datos, incluyendo periódicos reconocidos en Bolivia, proporcionó una base de datos como escenario base para el entrenamiento y evaluación del modelo. 

* La inclusión de diferentes categorías de noticias (economía, política e internacional) ayudó a crear un modelo de clasificacion de noticias.

# 9. Referencias bibliográficas

* Wikipedia. (s.f.). Minería de datos. Wikipedia, la enciclopedia libre. Recuperado de: https://es.wikipedia.org/wiki/Miner%C3%ADa_de_datos
* Revista Razón y Palabra. (2021). Uso de minería de datos para analizar las tendencias de consumo de noticias locales. Revista Razón y Palabra, 25(2), 45-59.
* CONICET. (2020). Minería de Datos, Conflictos Sociales y explotación de Recursos Naturales. Consejo Nacional de Investigaciones Científicas y Técnicas. Recuperado de: https://www.conicet.gov.ar/mineria-de-datos-conflictos-sociales-y-explotacion-de-recursos-naturales/
* Doblas, M.P. (2021) Clasificación de noticias mediante técnicas de procesamiento del lenguaje natural basadas en aprendizaje profundo. thesis. 
